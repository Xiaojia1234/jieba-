{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### “结巴”中文分词：做最好的 Python 中文分词组件\n",
    "\n",
    "\"Jieba\" (Chinese for \"to stutter\") Chinese text segmentation: built to be the best Python Chinese word segmentation module.\n",
    "\n",
    "Scroll down for English documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "支持三种分词模式：\n",
    "\n",
    "精确模式，试图将句子最精确地切开，适合文本分析；\n",
    "\n",
    "全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义；\n",
    "\n",
    "搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。\n",
    "\n",
    "支持繁体分词\n",
    "\n",
    "支持自定义词典\n",
    "\n",
    "MIT 授权协议"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 友情链接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/baidu/lac  百度中文词法分析（分词+词性+专名）系统\n",
    "\n",
    "https://github.com/baidu/AnyQ 百度FAQ自动问答系统\n",
    "\n",
    "https://github.com/baidu/Senta 百度情感识别系统"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 安装说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码对 Python 2/3 均兼容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全自动安装：easy_install jieba 或者 pip install jieba / pip3 install jieba\n",
    "\n",
    "半自动安装：先下载 http://pypi.python.org/pypi/jieba/ ，解压后运行 python setup.py install\n",
    "\n",
    "手动安装：将 jieba 目录放置于当前目录或者 site-packages 目录\n",
    "\n",
    "通过 import jieba 来引用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于前缀词典实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图 (DAG)\n",
    "\n",
    "采用了动态规划查找最大概率路径, 找出基于词频的最大切分组合\n",
    "\n",
    "对于未登录词，采用了基于汉字成词能力的 HMM 模型，使用了 Viterbi 算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 主要功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.分词"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "jieba.cut 方法接受三个输入参数: 需要分词的字符串；cut_all 参数用来控制是否采用全模式；HMM 参数用来控制是否使用 HMM 模型；\n",
    "\n",
    "jieba.cut_for_search 方法接受两个参数：需要分词的字符串；是否使用 HMM 模型。该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细；\n",
    "\n",
    "待分词的字符串可以是 unicode 或 UTF-8 字符串、GBK 字符串。注意：不建议直接输入 GBK 字符串，可能无法预料地错误解码成 UTF-8；\n",
    "\n",
    "jieba.cut 以及 jieba.cut_for_search 返回的结构都是一个可迭代的 generator，可以使用 for 循环来获得分词后得到的每一个词语(unicode)，或者用jieba.lcut 以及 jieba.lcut_for_search 直接返回 list；\n",
    "\n",
    "jieba.Tokenizer(dictionary=DEFAULT_DICT) 新建自定义分词器，可用于同时使用不同词典。jieba.dt 为默认分词器，所有全局分词相关函数都是该分词器的映射。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\darius\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.583 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学\n",
      "Default Mode: 我/ 来到/ 北京/ 清华大学\n",
      "他, 来到, 了, 网易, 杭研, 大厦\n",
      "小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造\n"
     ]
    }
   ],
   "source": [
    "# encoding=utf-8\n",
    "import jieba\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True)\n",
    "print(\"Full Mode: \" + \"/ \".join(seg_list))  # 全模式\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=False)\n",
    "print(\"Default Mode: \" + \"/ \".join(seg_list))  # 精确模式\n",
    "\n",
    "seg_list = jieba.cut(\"他来到了网易杭研大厦\")  # 默认是精确模式\n",
    "print(\", \".join(seg_list))\n",
    "\n",
    "seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\")  # 搜索引擎模式\n",
    "print(\", \".join(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.添加自定义词典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 载入词典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开发者可以指定自己自定义的词典，以便包含 jieba 词库里没有的词。虽然 jieba 有新词识别能力，但是自行添加新词可以保证更高的正确率\n",
    "\n",
    "用法： jieba.load_userdict(file_name) # file_name 为文件类对象或自定义词典的路径\n",
    "\n",
    "词典格式和 dict.txt 一样，一个词占一行；每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开，顺序不可颠倒。file_name 若为路径或二进制方式打开的文件，则文件必须为 UTF-8 编码。\n",
    "\n",
    "词频省略时使用自动计算的能保证分出该词的词频。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 例如："
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "创新办 3 i\n",
    "云计算 5\n",
    "凱特琳 nz\n",
    "台中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更改分词器（默认为 jieba.dt）的 tmp_dir 和 cache_file 属性，可分别指定缓存文件所在的文件夹及其文件名，用于受限的文件系统。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "范例："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义词典：https://github.com/fxsjy/jieba/blob/master/test/userdict.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用法示例：https://github.com/fxsjy/jieba/blob/master/test/test_userdict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之前： 李小福 / 是 / 创新 / 办 / 主任 / 也 / 是 / 云 / 计算 / 方面 / 的 / 专家 /\n",
    "\n",
    "加载自定义词库后：　李小福 / 是 / 创新办 / 主任 / 也 / 是 / 云计算 / 方面 / 的 / 专家 /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调整词典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 add_word(word, freq=None, tag=None) 和 del_word(word) 可在程序中动态修改词典。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 suggest_freq(segment, tune=True) 可调节单个词语的词频，使其能（或不能）被分出来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：自动计算的词频在使用 HMM 新词发现功能时可能无效。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果/放到/post/中将/出错/。\n"
     ]
    }
   ],
   "source": [
    " print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.suggest_freq(('中', '将'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果/放到/post/中/将/出错/。\n"
     ]
    }
   ],
   "source": [
    "print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「/台/中/」/正确/应该/不会/被/切开\n"
     ]
    }
   ],
   "source": [
    "print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.suggest_freq('台中', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「/台中/」/正确/应该/不会/被/切开\n"
     ]
    }
   ],
   "source": [
    "print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"通过用户自定义词典来增强歧义纠错能力\" --- https://github.com/fxsjy/jieba/issues/14\n",
    "关键词提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.关键词提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于 TF-IDF 算法的关键词抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.analyse"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())\n",
    "    sentence 为待提取的文本\n",
    "    topK 为返回几个 TF/IDF 权重最大的关键词，默认值为 20\n",
    "    withWeight 为是否一并返回关键词权重值，默认值为 False\n",
    "    allowPOS 仅包括指定词性的词，默认值为空，即不筛选\n",
    "    \n",
    "jieba.analyse.TFIDF(idf_path=None) 新建 TFIDF 实例，idf_path 为 IDF 频率文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码示例 （关键词提取）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/fxsjy/jieba/blob/master/test/extract_tags.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关键词提取所使用逆向文件频率（IDF）文本语料库可以切换成自定义语料库的路径\n",
    "\n",
    "    用法： jieba.analyse.set_idf_path(file_name) # file_name为自定义语料库的路径\n",
    "    自定义语料库示例：https://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.big\n",
    "    用法示例：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关键词提取所使用停止词（Stop Words）文本语料库可以切换成自定义语料库的路径\n",
    "\n",
    "    用法： jieba.analyse.set_stop_words(file_name) # file_name为自定义语料库的路径\n",
    "    自定义语料库示例：https://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txt\n",
    "    用法示例：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关键词一并返回关键词权重值示例\n",
    "\n",
    "    用法示例：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_with_weight.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于 TextRank 算法的关键词抽取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v')) 直接使用，接口相同，注意默认过滤词性。\n",
    "\n",
    "jieba.analyse.TextRank() 新建自定义 TextRank 实例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "算法论文： TextRank: Bringing Order into Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本思想:\n",
    "\n",
    "    将待抽取关键词的文本进行分词\n",
    "    以固定窗口大小(默认为5，通过span属性调整)，词之间的共现关系，构建图\n",
    "    计算图中节点的PageRank，注意是无向带权图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "见 test/demo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.词性标注"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jieba.posseg.POSTokenizer(tokenizer=None) 新建自定义分词器，tokenizer 参数可指定内部使用的 jieba.Tokenizer 分词器。jieba.posseg.dt 为默认词性标注分词器。\n",
    "\n",
    "标注句子分词后每个词的词性，采用和 ictclas 兼容的标记法。\n",
    "用法示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 r\n",
      "爱 v\n",
      "北京 ns\n",
      "天安门 ns\n"
     ]
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "words = pseg.cut(\"我爱北京天安门\")\n",
    "for word, flag in words:\n",
    "    print('%s %s' % (word, flag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.并行分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原理：将目标文本按行分隔后，把各行文本分配到多个 Python 进程并行分词，然后归并结果，从而获得分词速度的可观提升\n",
    "\n",
    "基于 python 自带的 multiprocessing 模块，目前暂不支持 Windows\n",
    "\n",
    "用法："
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "jieba.enable_parallel(4) # 开启并行分词模式，参数为并行进程数\n",
    "jieba.disable_parallel() # 关闭并行分词模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例子：https://github.com/fxsjy/jieba/blob/master/test/parallel/test_file.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验结果：在 4 核 3.4GHz Linux 机器上，对金庸全集进行精确分词，获得了 1MB/s 的速度，是单进程版的 3.3 倍。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：并行分词仅支持默认分词器 jieba.dt 和 jieba.posseg.dt。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Tokenize：返回词语在原文的起止位置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，输入参数只接受 unicode\n",
    "\n",
    "默认模式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word 永和\t\t start: 0 \t\t end:2\n",
      "word 服装\t\t start: 2 \t\t end:4\n",
      "word 饰品\t\t start: 4 \t\t end:6\n",
      "word 有限公司\t\t start: 6 \t\t end:10\n"
     ]
    }
   ],
   "source": [
    "result = jieba.tokenize(u'永和服装饰品有限公司')\n",
    "for tk in result:\n",
    "    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "搜索模式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word 永和\t\t start: 0 \t\t end:2\n",
      "word 服装\t\t start: 2 \t\t end:4\n",
      "word 饰品\t\t start: 4 \t\t end:6\n",
      "word 有限\t\t start: 6 \t\t end:8\n",
      "word 公司\t\t start: 8 \t\t end:10\n",
      "word 有限公司\t\t start: 6 \t\t end:10\n"
     ]
    }
   ],
   "source": [
    "result = jieba.tokenize(u'永和服装饰品有限公司', mode='search')\n",
    "for tk in result:\n",
    "    print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.ChineseAnalyzer for Whoosh 搜索引擎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引用： from jieba.analyse import ChineseAnalyzer\n",
    "\n",
    "用法示例：https://github.com/fxsjy/jieba/blob/master/test/test_whoosh.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.命令行分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用示例：python -m jieba news.txt > cut_result.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "命令行选项（翻译）："
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "使用: python -m jieba [options] filename\n",
    "\n",
    "结巴命令行界面。\n",
    "\n",
    "固定参数:\n",
    "  filename              输入文件\n",
    "\n",
    "可选参数:\n",
    "  -h, --help            显示此帮助信息并退出\n",
    "  -d [DELIM], --delimiter [DELIM]\n",
    "                        使用 DELIM 分隔词语，而不是用默认的' / '。\n",
    "                        若不指定 DELIM，则使用一个空格分隔。\n",
    "  -p [DELIM], --pos [DELIM]\n",
    "                        启用词性标注；如果指定 DELIM，词语和词性之间\n",
    "                        用它分隔，否则用 _ 分隔\n",
    "  -D DICT, --dict DICT  使用 DICT 代替默认词典\n",
    "  -u USER_DICT, --user-dict USER_DICT\n",
    "                        使用 USER_DICT 作为附加词典，与默认词典或自定义词典配合使用\n",
    "  -a, --cut-all         全模式分词（不支持词性标注）\n",
    "  -n, --no-hmm          不使用隐含马尔可夫模型\n",
    "  -q, --quiet           不输出载入信息到 STDERR\n",
    "  -V, --version         显示版本信息并退出\n",
    "\n",
    "如果没有指定文件名，则使用标准输入。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--help 选项输出："
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$> python -m jieba --help\n",
    "Jieba command line interface.\n",
    "\n",
    "positional arguments:\n",
    "  filename              input file\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  -d [DELIM], --delimiter [DELIM]\n",
    "                        use DELIM instead of ' / ' for word delimiter; or a\n",
    "                        space if it is used without DELIM\n",
    "  -p [DELIM], --pos [DELIM]\n",
    "                        enable POS tagging; if DELIM is specified, use DELIM\n",
    "                        instead of '_' for POS delimiter\n",
    "  -D DICT, --dict DICT  use DICT as dictionary\n",
    "  -u USER_DICT, --user-dict USER_DICT\n",
    "                        use USER_DICT together with the default dictionary or\n",
    "                        DICT (if specified)\n",
    "  -a, --cut-all         full pattern cutting (ignored with POS tagging)\n",
    "  -n, --no-hmm          don't use the Hidden Markov Model\n",
    "  -q, --quiet           don't print loading messages to stderr\n",
    "  -V, --version         show program's version number and exit\n",
    "\n",
    "If no filename specified, use STDIN instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 延迟加载机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jieba 采用延迟加载，import jieba 和 jieba.Tokenizer() 不会立即触发词典的加载，一旦有必要才开始加载词典构建前缀字典。如果你想手工初始 jieba，也可以手动初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "jieba.initialize()  # 手动初始化（可选）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 0.28 之前的版本是不能指定主词典的路径的，有了延迟加载机制后，你可以改变主词典的路径:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "jieba.set_dictionary('data/dict.txt.big')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "例子： https://github.com/fxsjy/jieba/blob/master/test/test_change_dictpath.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 其他词典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1，占用内存较小的词典文件 https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.small\n",
    "\n",
    "支持繁体分词更好的词典文件 https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.big\n",
    "\n",
    "2/下载你所需要的词典，然后覆盖 jieba/dict.txt 即可；或者用 jieba.set_dictionary('data/dict.txt.big')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 其他语言实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结巴分词 Java 版本\n",
    "作者：piaolingxue 地址：https://github.com/huaban/jieba-analysis\n",
    "\n",
    "结巴分词 C++ 版本\n",
    "作者：yanyiwu 地址：https://github.com/yanyiwu/cppjieba\n",
    "\n",
    "结巴分词 Node.js 版本\n",
    "作者：yanyiwu 地址：https://github.com/yanyiwu/nodejieba\n",
    "\n",
    "结巴分词 Erlang 版本\n",
    "作者：falood 地址：https://github.com/falood/exjieba\n",
    "\n",
    "结巴分词 R 版本\n",
    "作者：qinwf 地址：https://github.com/qinwf/jiebaR\n",
    "\n",
    "结巴分词 iOS 版本\n",
    "作者：yanyiwu 地址：https://github.com/yanyiwu/iosjieba\n",
    "\n",
    "结巴分词 PHP 版本\n",
    "作者：fukuball 地址：https://github.com/fukuball/jieba-php\n",
    "\n",
    "结巴分词 .NET(C#) 版本\n",
    "作者：anderscui 地址：https://github.com/anderscui/jieba.NET/\n",
    "\n",
    "结巴分词 Go 版本\n",
    "作者: wangbin 地址: https://github.com/wangbin/jiebago\n",
    "作者: yanyiwu 地址: https://github.com/yanyiwu/gojieba\n",
    "\n",
    "结巴分词Android版本\n",
    "作者 Dongliang.W 地址：https://github.com/452896915/jieba-android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 系统集成\n",
    "\n",
    "Solr: https://github.com/sing1ee/jieba-solr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词速度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 MB / Second in Full Mode\n",
    "\n",
    "400 KB / Second in Default Mode\n",
    "\n",
    "测试环境: Intel(R) Core(TM) i7-2600 CPU @ 3.4GHz；《围城》.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
